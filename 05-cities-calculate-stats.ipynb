{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.1\n",
      "2.1\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "ox.config(use_cache=True,\n",
    "          log_file=True,\n",
    "          log_console=True,\n",
    "          log_filename='calculate-cities',\n",
    "          cache_folder=config.cities_cache_folder)\n",
    "\n",
    "print(ox.__version__)\n",
    "print(nx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphml_folder = config.cities_graphml_folder\n",
    "places_folder = 'input_data/places' #tiger place shapefiles\n",
    "stats_folder = config.cities_stats_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = []\n",
    "for state_folder in os.listdir(graphml_folder):\n",
    "    for city_file in os.listdir('{}/{}'.format(graphml_folder, state_folder)):\n",
    "\n",
    "        data = {}\n",
    "        data['state_folder'] = state_folder\n",
    "        data['state_fips'] = state_folder.split('_')[0]\n",
    "        data['state'] = state_folder.split('_')[1]\n",
    "        data['city_file'] = city_file\n",
    "        data['geoid'] = city_file.split('_')[0]\n",
    "        data['city'] = city_file.strip('_{}'.format(data['geoid'])).replace('.graphml', '').replace('_', ' ')\n",
    "        places.append(data)\n",
    "\n",
    "df = pd.DataFrame(places)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get land area data from shapefiles and merge into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load each state shapefile and get the geoid and aland for each city row\n",
    "gdf = gpd.GeoDataFrame()\n",
    "for state_fips in df['state_fips'].unique():\n",
    "    path = '{}/tl_2017_{}_place'.format(places_folder, state_fips)\n",
    "    gdf = gdf.append(gpd.read_file(path)[['GEOID', 'ALAND']])\n",
    "\n",
    "# merge aland values into dataframe, on geoid\n",
    "gdf = gdf.rename(columns=str.lower)\n",
    "df = pd.merge(df, gdf, how='left', on='geoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load graph and calculate stats for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_get_stats(row):\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        folder = '{}/{}'.format(graphml_folder, row['state_folder'])\n",
    "        G = ox.load_graphml(filename=row['city_file'], folder=folder)\n",
    "        \n",
    "        stats = ox.basic_stats(G, area=row['aland'])\n",
    "        \n",
    "        # unpack k-counts and k-proportion dicts into individiual keys:values\n",
    "        for k, count in stats['streets_per_node_counts'].items():\n",
    "            stats['int_{}_streets_count'.format(k)] = count\n",
    "        for k, proportion in stats['streets_per_node_proportion'].items():\n",
    "            stats['int_{}_streets_prop'.format(k)] = proportion\n",
    "            \n",
    "        # calculate/drop the extended stats that have values per node\n",
    "        extended_stats = ox.extended_stats(G)\n",
    "        se = pd.Series(extended_stats)\n",
    "        se = se.drop(['avg_neighbor_degree', 'avg_weighted_neighbor_degree', 'clustering_coefficient',\n",
    "                      'clustering_coefficient_weighted', 'degree_centrality', 'pagerank'])\n",
    "        extended_stats_clean = se.to_dict()\n",
    "        \n",
    "        for key in extended_stats_clean:\n",
    "            stats[key] = extended_stats_clean[key]\n",
    "        \n",
    "        stats['area_km'] = row['aland'] / 1e6        \n",
    "        stats['city'] = row['city']\n",
    "        stats['state'] = row['state']\n",
    "        stats['geoid'] = row['geoid']\n",
    "        stats['area'] = row['aland']\n",
    "        stats['time'] = time.time()-start_time\n",
    "        \n",
    "        return pd.Series(stats)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('{}, {} failed: {}'.format(row['city'], row['state'], e))\n",
    "        return pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\geoff\\dropbox\\documents\\school\\phd\\projects\\code\\osmnx-repos\\osmnx\\osmnx\\stats.py:201: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  circuity_avg = edge_length_total / gc_distances.sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lake Aluma, OK failed: float division by zero\n",
      "Ophir, UT failed: float division by zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19642, 67)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample = list(range(0, len(df), int(len(df)/100)))\n",
    "#stats = df.iloc[sample].apply(load_graph_get_stats, axis=1)\n",
    "stats_temp = df.apply(load_graph_get_stats, axis=1)\n",
    "stats_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6466.0165383815765"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_temp['time'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = stats_temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stuff to drop\n",
    "cols_to_drop = ['area', 'time', 'streets_per_node_counts', 'streets_per_node_proportion', \n",
    "                'pagerank_max_node', 'pagerank_min_node', 'clean_intersection_count',\n",
    "                'clean_intersection_density_km']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rename = {}\n",
    "for col in stats.columns:\n",
    "    if 'int_' in col:\n",
    "        n = col.split('_')[1]\n",
    "        if n not in ['1', '3', '4']:\n",
    "            cols_to_drop.append(col)\n",
    "        else:\n",
    "            suffix = 'count' if 'count' in col else 'proportion'\n",
    "            cols_to_rename[col] = 'intersect_{}way_{}'.format(n, suffix)\n",
    "            \n",
    "stats = stats.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename these to friendlier names\n",
    "cols_to_rename['clustering_coefficient_avg'] = 'cluster_coeff_avg'\n",
    "cols_to_rename['clustering_coefficient_weighted_avg'] = 'cluster_coeff_weighted_avg'\n",
    "cols_to_rename['intersection_density_km'] = 'intersect_density_km'\n",
    "cols_to_rename['intersect_1way_count'] = 'dead_end_count'\n",
    "cols_to_rename['intersect_1way_proportion'] = 'dead_end_proportion'\n",
    "cols_to_rename['m'] = 'edge_count'\n",
    "cols_to_rename['n'] = 'node_count'\n",
    "stats = stats.rename(columns=cols_to_rename)\n",
    "stats = stats.rename(columns=cols_to_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop anything lacking a GEOID\n",
    "stats = stats.dropna(subset=['geoid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make these integers\n",
    "cols_int = ['intersection_count', 'edge_length_total', 'edge_count', 'node_count', 'street_segments_count']\n",
    "stats[cols_int] = stats[cols_int].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make city, state, geoid at left of df\n",
    "cols = stats.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index('city')))\n",
    "cols.insert(1, cols.pop(cols.index('state')))\n",
    "cols.insert(2, cols.pop(cols.index('geoid')))\n",
    "stats = stats.reindex(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19640, 33)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city', 'state', 'geoid', 'area_km', 'avg_neighbor_degree_avg',\n",
       "       'avg_weighted_neighbor_degree_avg', 'circuity_avg', 'cluster_coeff_avg',\n",
       "       'cluster_coeff_weighted_avg', 'degree_centrality_avg',\n",
       "       'edge_density_km', 'edge_length_avg', 'edge_length_total',\n",
       "       'dead_end_count', 'dead_end_proportion', 'intersect_3way_count',\n",
       "       'intersect_3way_proportion', 'intersect_4way_count',\n",
       "       'intersect_4way_proportion', 'intersection_count',\n",
       "       'intersect_density_km', 'k_avg', 'edge_count', 'node_count',\n",
       "       'node_density_km', 'pagerank_max', 'pagerank_min',\n",
       "       'self_loop_proportion', 'street_density_km', 'street_length_avg',\n",
       "       'street_length_total', 'street_segments_count', 'streets_per_node_avg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>geoid</th>\n",
       "      <th>area_km</th>\n",
       "      <th>avg_neighbor_degree_avg</th>\n",
       "      <th>avg_weighted_neighbor_degree_avg</th>\n",
       "      <th>circuity_avg</th>\n",
       "      <th>cluster_coeff_avg</th>\n",
       "      <th>cluster_coeff_weighted_avg</th>\n",
       "      <th>degree_centrality_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>node_count</th>\n",
       "      <th>node_density_km</th>\n",
       "      <th>pagerank_max</th>\n",
       "      <th>pagerank_min</th>\n",
       "      <th>self_loop_proportion</th>\n",
       "      <th>street_density_km</th>\n",
       "      <th>street_length_avg</th>\n",
       "      <th>street_length_total</th>\n",
       "      <th>street_segments_count</th>\n",
       "      <th>streets_per_node_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbeville</td>\n",
       "      <td>AL</td>\n",
       "      <td>0100124</td>\n",
       "      <td>40.255362</td>\n",
       "      <td>2.762393</td>\n",
       "      <td>0.035414</td>\n",
       "      <td>1.068647</td>\n",
       "      <td>0.044160</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.014098</td>\n",
       "      <td>...</td>\n",
       "      <td>351</td>\n",
       "      <td>8.719335</td>\n",
       "      <td>0.008352</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.013857</td>\n",
       "      <td>2257.800737</td>\n",
       "      <td>200.637055</td>\n",
       "      <td>90888.586</td>\n",
       "      <td>453</td>\n",
       "      <td>2.598291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adamsville</td>\n",
       "      <td>AL</td>\n",
       "      <td>0100460</td>\n",
       "      <td>65.211854</td>\n",
       "      <td>2.720997</td>\n",
       "      <td>0.028521</td>\n",
       "      <td>1.099474</td>\n",
       "      <td>0.042593</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.007590</td>\n",
       "      <td>...</td>\n",
       "      <td>612</td>\n",
       "      <td>9.384797</td>\n",
       "      <td>0.006342</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>2345.979904</td>\n",
       "      <td>206.180187</td>\n",
       "      <td>152985.699</td>\n",
       "      <td>742</td>\n",
       "      <td>2.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Addison</td>\n",
       "      <td>AL</td>\n",
       "      <td>0100484</td>\n",
       "      <td>9.753292</td>\n",
       "      <td>2.760518</td>\n",
       "      <td>0.021447</td>\n",
       "      <td>1.056957</td>\n",
       "      <td>0.064725</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>0.046450</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>10.560537</td>\n",
       "      <td>0.023818</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>2881.086714</td>\n",
       "      <td>228.455935</td>\n",
       "      <td>28100.080</td>\n",
       "      <td>123</td>\n",
       "      <td>2.543689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akron</td>\n",
       "      <td>AL</td>\n",
       "      <td>0100676</td>\n",
       "      <td>1.776163</td>\n",
       "      <td>3.248485</td>\n",
       "      <td>0.036485</td>\n",
       "      <td>1.075132</td>\n",
       "      <td>0.093939</td>\n",
       "      <td>0.021408</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>30.965626</td>\n",
       "      <td>0.039553</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5186.226715</td>\n",
       "      <td>122.821120</td>\n",
       "      <td>9211.584</td>\n",
       "      <td>75</td>\n",
       "      <td>2.836364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabaster</td>\n",
       "      <td>AL</td>\n",
       "      <td>0100820</td>\n",
       "      <td>65.217462</td>\n",
       "      <td>2.717090</td>\n",
       "      <td>0.028984</td>\n",
       "      <td>1.091252</td>\n",
       "      <td>0.029031</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>...</td>\n",
       "      <td>1813</td>\n",
       "      <td>27.799303</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.004482</td>\n",
       "      <td>5247.764962</td>\n",
       "      <td>164.068031</td>\n",
       "      <td>342245.912</td>\n",
       "      <td>2086</td>\n",
       "      <td>2.357970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         city state    geoid    area_km  avg_neighbor_degree_avg  \\\n",
       "0   Abbeville    AL  0100124  40.255362                 2.762393   \n",
       "1  Adamsville    AL  0100460  65.211854                 2.720997   \n",
       "2     Addison    AL  0100484   9.753292                 2.760518   \n",
       "3       Akron    AL  0100676   1.776163                 3.248485   \n",
       "4   Alabaster    AL  0100820  65.217462                 2.717090   \n",
       "\n",
       "   avg_weighted_neighbor_degree_avg  circuity_avg  cluster_coeff_avg  \\\n",
       "0                          0.035414      1.068647           0.044160   \n",
       "1                          0.028521      1.099474           0.042593   \n",
       "2                          0.021447      1.056957           0.064725   \n",
       "3                          0.036485      1.075132           0.093939   \n",
       "4                          0.028984      1.091252           0.029031   \n",
       "\n",
       "   cluster_coeff_weighted_avg  degree_centrality_avg          ...           \\\n",
       "0                    0.002017               0.014098          ...            \n",
       "1                    0.002074               0.007590          ...            \n",
       "2                    0.005696               0.046450          ...            \n",
       "3                    0.021408               0.101010          ...            \n",
       "4                    0.001685               0.002445          ...            \n",
       "\n",
       "   node_count  node_density_km  pagerank_max  pagerank_min  \\\n",
       "0         351         8.719335      0.008352      0.000432   \n",
       "1         612         9.384797      0.006342      0.000255   \n",
       "2         103        10.560537      0.023818      0.001468   \n",
       "3          55        30.965626      0.039553      0.002770   \n",
       "4        1813        27.799303      0.001746      0.000084   \n",
       "\n",
       "   self_loop_proportion  street_density_km  street_length_avg  \\\n",
       "0              0.013857        2257.800737         200.637055   \n",
       "1              0.001409        2345.979904         206.180187   \n",
       "2              0.008197        2881.086714         228.455935   \n",
       "3              0.000000        5186.226715         122.821120   \n",
       "4              0.004482        5247.764962         164.068031   \n",
       "\n",
       "   street_length_total  street_segments_count  streets_per_node_avg  \n",
       "0            90888.586                    453              2.598291  \n",
       "1           152985.699                    742              2.694444  \n",
       "2            28100.080                    123              2.543689  \n",
       "3             9211.584                     75              2.836364  \n",
       "4           342245.912                   2086              2.357970  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(stats_folder):\n",
    "    os.makedirs(stats_folder)\n",
    "output_path = '{}/cities-stats.csv'.format(stats_folder)\n",
    "stats.to_csv(output_path, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
